{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6da588",
   "metadata": {},
   "source": [
    "# **Buckle Up ! We are starting our week 2 roller coaster**\n",
    "\n",
    "In our first week we covered some theoritical concepts and completed our setup so its time we start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b55c5",
   "metadata": {},
   "source": [
    "## üìì**Conversational AI Concepts & Model Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7ace2",
   "metadata": {},
   "source": [
    "üéØ By the end of this week, you will:\n",
    "\n",
    "- Understand LLMs, STT, TTS models and their roles.\n",
    "\n",
    "- Know how to connect to LLMs with APIs (Groq as example).\n",
    "\n",
    "- Use Python (requests + JSON) for API interaction.\n",
    "\n",
    "- Start building a basic chatbot with memory and preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c5144",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåü Large Language Models (LLMs) üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03968dc4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚ùó **Question 1**: What is an LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd894fc",
   "metadata": {},
   "source": [
    "üëâ It‚Äôs like a super-smart text predictor that can read, understand, and generate human-like sentences.\n",
    "\n",
    "You give it some words ‚Üí it guesses the next words in a way that makes sense.\n",
    "\n",
    "For example:\n",
    "\n",
    "1) You ask a question ‚Üí it gives you an answer.\n",
    "\n",
    "2) You write a sentence ‚Üí it can complete it.\n",
    "\n",
    "3) You give it a topic ‚Üí it can write an essay, code, or even a story.\n",
    "\n",
    "So, its a type of AI trained on huge amounts of text data to generate or understand text.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77076ddc",
   "metadata": {},
   "source": [
    "### Types of LLMs\n",
    "\n",
    "1. Encoder-only models (e.g., BERT)\n",
    "\n",
    "    - Best for understanding text (classification, sentiment analysis, embeddings).\n",
    "\n",
    "    - ‚ùå Not good at generating text.\n",
    "\n",
    "2. Decoder-only models (e.g., GPT, LLaMA, Mistral)\n",
    "\n",
    "    - Best for text generation (chatbots, writing, summarization).\n",
    "\n",
    "    - What we use in chatbots.\n",
    "\n",
    "3. Encoder-decoder models (e.g., T5, BART)\n",
    "\n",
    "    - Good at transforming text (translation, summarization, Q&A)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339099fe",
   "metadata": {},
   "source": [
    "### Must-Knows about LLMs\n",
    "\n",
    "- They don‚Äôt ‚Äúthink‚Äù like humans ‚Üí They predict text based on training.\n",
    "\n",
    "- Garbage in ‚Üí garbage out: Poor prompts = poor answers.\n",
    "\n",
    "- Token limits: Models can only ‚Äúsee‚Äù a certain number of words at a time.\n",
    "\n",
    "- Biases: Trained on internet text ‚Üí may reflect biases/errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b2dd4",
   "metadata": {},
   "source": [
    "### üí° **Quick Questions**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753565a",
   "metadata": {},
   "source": [
    "1. Why might a chatbot built on BERT (encoder-only) struggle to answer open-ended questions?\n",
    "\n",
    "- Answer üëâ BERT is great at understanding text but can‚Äôt really generate answers because it‚Äôs encoder only. It can find relevant info but struggles with open ended questions since it doesn‚Äôt have a decoder to produce free form text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5feffca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåü Speech-to-Text (STT) üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393abf7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚ùó **Question 2**: What is STT?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f54ac00",
   "metadata": {},
   "source": [
    "üëâ listens to your voice and turns it into written text.\n",
    "\n",
    "- Converts **audio ‚Üí text**.\n",
    "- Enables voice input for conversational AI.\n",
    "- Think of it as the **ears** of the chatbot.\n",
    "\n",
    "**Popular STT Models**:\n",
    "\n",
    "1) **Whisper (OpenAI)** ‚Äì strong at multilingual speech recognition.\n",
    "2) **Google Speech-to-Text API** ‚Äì widely used, real-time transcription.\n",
    "3) **Vosk** ‚Äì lightweight, offline speech recognition.\n",
    "\n",
    "**Common Usages**\n",
    "\n",
    "1) Voice assistants (Alexa, Siri, Google Assistant).\n",
    "2) Automated captions in meetings or lectures.\n",
    "3) Voice-enabled customer support.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99714c",
   "metadata": {},
   "source": [
    "### Must-Knows about STT\n",
    "\n",
    "- Accuracy depends on **noise, accents, clarity of speech**.\n",
    "\n",
    "- Some models need **internet connection** (API-based), others run **offline**.\n",
    "\n",
    "- Preprocessing audio (noise reduction) improves results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec23bf9a",
   "metadata": {},
   "source": [
    "### üí° **Quick Questions**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407d8a82",
   "metadata": {},
   "source": [
    "2. Why do you think meeting transcription apps like Zoom or Google Meet struggle when multiple people talk at once?\n",
    "\n",
    "- Answer üëâ When multiple people talk at once, overlapping speech makes it hard for the system to separate voices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2959a81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåü Text-to-Speech (TTS) üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6650b62d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚ùó **Question 3**: What is TTS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ec8ef",
   "metadata": {},
   "source": [
    "üëâ takes written text and speaks it out loud in a human-like voice.\n",
    "\n",
    "- Converts **text ‚Üí audio (speech)**.\n",
    "- Think of it as the **mouth** of the chatbot.\n",
    "- Makes AI ‚Äúspeak‚Äù naturally.\n",
    "\n",
    "**Popular TTS Models**:\n",
    "\n",
    "1) **Google TTS** ‚Äì supports many languages and voices.\n",
    "2) **Amazon Polly** ‚Äì lifelike voice synthesis with customization.\n",
    "3) **ElevenLabs** ‚Äì cutting-edge, realistic voice cloning.\n",
    "\n",
    "**Common Usages**\n",
    "\n",
    "1) Screen readers for visually impaired users.\n",
    "2) AI chatbots with voice output.\n",
    "3) Audiobooks or podcast generation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb2471",
   "metadata": {},
   "source": [
    "### Must-Knows about TTS\n",
    "\n",
    "- Some voices sound robotic; others use **neural TTS** for natural tones.\n",
    "\n",
    "- Latency matters ‚Üí If too slow, conversation feels unnatural.\n",
    "\n",
    "- Some TTS services allow **custom voices**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49cb51",
   "metadata": {},
   "source": [
    "### üí° **Quick Questions**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f3eb2",
   "metadata": {},
   "source": [
    "3. If you were designing a voice-based AI tutor, what qualities would you want in its TTS voice (tone, speed, clarity, etc.)?\n",
    "\n",
    "- Answer üëâ I‚Äôd want a clear, friendly, and engaging tone that feels approachable. The speed should be fast enough to stay efficient but slow enough for learners to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8042c582",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåü Using APIs for LLMs with Groq üåü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889d8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational AI refers to the technology that enables computers or digital systems to simulate human-like conversations with humans. This is achieved through the use of natural language processing (NLP) and machine learning algorithms that allow AI systems to understand, interpret, and respond to human input in a way that feels natural and intuitive.\n",
      "\n",
      "Conversational AI can take many forms, including:\n",
      "\n",
      "1. **Chatbots**: These are AI-powered software programs that can engage in text-based conversations with humans, often used to provide customer support, answer frequently asked questions, or facilitate transactions.\n",
      "2. **Virtual assistants**: These are AI-powered digital assistants, such as Siri, Google Assistant, or Alexa, that can understand voice commands and respond with relevant information or actions.\n",
      "3. **Voice-controlled interfaces**: These are AI-powered interfaces that allow users to interact with devices using voice commands, such as smart speakers or home automation systems.\n",
      "4. **Live chat applications**: These are AI-powered chat platforms that allow humans to interact with companies or organizations in real-time, often used for customer support or sales purposes.\n",
      "\n",
      "The key characteristics of conversational AI include:\n",
      "\n",
      "1. **Natural language understanding**: The ability to comprehend human language and syntax.\n",
      "2. **Contextual understanding**: The ability to understand the context of the conversation and respond accordingly.\n",
      "3. **Sentiment analysis**: The ability to recognize and respond to emotions and tone.\n",
      "4. **Flexibility**: The ability to adapt to changing conversation flows and user inputs.\n",
      "\n",
      "Conversational AI has many applications, including:\n",
      "\n",
      "1. **Customer service**: AI-powered chatbots can provide 24/7 customer support and answer frequently asked questions.\n",
      "2. **Sales**: Conversational AI can be used to engage with customers, answer product inquiries, and facilitate transactions.\n",
      "3. **Healthcare**: Conversational AI can be used to provide patient support, answer medical questions, and facilitate health education.\n",
      "4. **Education**: Conversational AI can be used to provide personalized feedback, answer student questions, and facilitate learning.\n",
      "\n",
      "Overall, conversational AI has the potential to revolutionize the way we interact with technology and each other, making communication more natural, intuitive, and accessible.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello! What is conversational AI?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c20eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåü Assignments üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc2ce6",
   "metadata": {},
   "source": [
    "### üìù Assignment 1: LLM Understanding\n",
    "\n",
    "* Write a short note (3‚Äì4 sentences) explaining the difference between **encoder-only, decoder-only, and encoder-decoder LLMs**.\n",
    "* Give one example usage of each.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Encoder-only models focus on understanding text. They‚Äôre great for tasks like classification or extracting answers from a passage. Example: BERT for sentiment analysis.\n",
    "\n",
    "Decoder-only models generate text based on a prompt, predicting one token at a time. Example: GPT for chat or story generation.\n",
    "\n",
    "Encoder-decoder models both understand input and generate output, making them ideal for translation or summarization. Example: T5 for text summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370084b8",
   "metadata": {},
   "source": [
    "### üìù Assignment 2: STT/TTS Exploration\n",
    "\n",
    "* Find **one STT model** and **one TTS model** (other than Whisper/Google).\n",
    "* Write down:\n",
    "\n",
    "  * What it does.\n",
    "  * One possible application.\n",
    "\n",
    "TTS model: ElevenLabs. Produces highly realistic, human-like speech from text; Application: Audiobook narration or personalized AI tutors.\n",
    "\n",
    "STT model: Mozilla DeepSpeech. converts spoken language into text using a neural network; Application: Dictation software or voice controlled apps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84824b65",
   "metadata": {},
   "source": [
    "### üìù Assignment 3: Build a Chatbot with Memory\n",
    "\n",
    "* Write a Python program that:\n",
    "\n",
    "  * Takes user input in a loop.\n",
    "  * Sends it to Groq API.\n",
    "  * Stores the last 5 messages in memory.\n",
    "  * Ends when user types `\"quit\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1cb5a4-856d-4dd1-b6cd-9c219ef16f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type message ('quit' to exit):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: Hello, how can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: I'm an artificial intelligence (AI) model called a conversational AI or chatbot. My purpose is to assist and communicate with you through text-based conversations. I'm designed to understand and respond to a wide range of questions and topics.\n",
      "\n",
      "I don't have a personal identity, emotions, or consciousness like a human being. I'm a software program running on computer servers, trained on a massive dataset of text to learn patterns and relationships.\n",
      "\n",
      "I can help with:\n",
      "\n",
      "- Answering questions on various topics, such as history, science, entertainment, and more\n",
      "- Generating text, like stories or summaries\n",
      "- Translating languages\n",
      "- Providing definitions and explanations\n",
      "- Chatting in a friendly, natural-sounding way (like this conversation!)\n",
      "\n",
      "Feel free to ask me anything, and I'll do my best to help!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  whats my name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: Unfortunately, I don't know your name yet. This is the start of our conversation, and I don't have any prior information about you. If you'd like, you can share your name with me, and I can use it in our conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Rayan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: Nice to meet you, Rayan. It's good to know your name. Now that I have it, I can refer to you personally in our conversation. How's your day going so far?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  whats my name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: Your name is Rayan. You just told me!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Tell the full form of GPT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: The full form of GPT is Generative Pre-trained Transformer.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  perfect\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: Glad I could get it right, Rayan. If you have any more questions or topics you'd like to discuss, feel free to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  whats Man City\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: Manchester City, commonly referred to as Man City, is an English professional football club based in Manchester, England. They are a prominent team in the Premier League, one of England's top-tier football leagues. The team has undergone significant transformations and has achieved numerous successes in recent years, making them one of the most successful and popular football clubs in the world.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  great\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: Glad I could provide some info, Rayan. Do you have a favorite team or player?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: It was nice chatting with you, Rayan. Goodbye!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"-removed-\")\n",
    "history = []\n",
    "\n",
    "print(\"Type message ('quit' to exit):\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        print(\"Exiting.\")\n",
    "        break\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    if len(history) > 10:\n",
    "        history = history[-10:]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    if len(history) > 10:\n",
    "        history = history[-10:]\n",
    "\n",
    "    print(\"Groq:\", reply)\n",
    "\n",
    "def showHistory():\n",
    "    print(\"\\nHistory:\\n\")\n",
    "    for msg in history:\n",
    "        role = \"You\" if msg[\"role\"] == \"user\" else \"Groq\"\n",
    "        print(f\"{role}: {msg['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f56008-fff8-405c-b120-88c36d5c189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "History:\n",
      "\n",
      "You: Tell the full form of GPT\n",
      "Groq: The full form of GPT is Generative Pre-trained Transformer.\n",
      "You: perfect\n",
      "Groq: Glad I could get it right, Rayan. If you have any more questions or topics you'd like to discuss, feel free to ask!\n",
      "You: whats Man City\n",
      "Groq: Manchester City, commonly referred to as Man City, is an English professional football club based in Manchester, England. They are a prominent team in the Premier League, one of England's top-tier football leagues. The team has undergone significant transformations and has achieved numerous successes in recent years, making them one of the most successful and popular football clubs in the world.\n",
      "You: great\n",
      "Groq: Glad I could provide some info, Rayan. Do you have a favorite team or player?\n",
      "You: exit\n",
      "Groq: It was nice chatting with you, Rayan. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "showHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef3132",
   "metadata": {},
   "source": [
    "### üìù Assignment 4: Preprocessing Function\n",
    "\n",
    "* Write a function to clean user input:\n",
    "\n",
    "  * Lowercase text.\n",
    "  * Remove punctuation.\n",
    "  * Strip extra spaces.\n",
    "\n",
    "Test with: `\"  HELLo!!!  How ARE you?? \"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776b1303-d2ca-4a7d-bcaa-2de60e399084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are you\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "text = \"  HELLo!!!  How ARE you?? \"\n",
    "ans = preprocessing(text)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53027998",
   "metadata": {},
   "source": [
    "### üìù Assignment 5: Text Preprocessing\n",
    "\n",
    "* Write a function that:\n",
    "\n",
    "    * Converts text to lowercase.\n",
    "    * Removes punctuation & numbers.\n",
    "    * Removes stopwords (`the, is, and...`).\n",
    "    * Applies stemming or lemmatization.\n",
    "    * Removes words shorter than 3 characters.\n",
    "    * Keeps only nouns, verbs, and adjectives (using POS tagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e02ea6-3c70-47ee-9a8b-d35ed39a4f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'rayan']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def getWordnetPOS(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def preprocessText(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in set(stopwords.words('english')) and len(w) >= 3]\n",
    "    posTokens = pos_tag(tokens)\n",
    "    filteredTokens = []\n",
    "    for word, tag in posTokens:\n",
    "        wntag = getWordnetPOS(tag)\n",
    "        if wntag:\n",
    "            filteredTokens.append(lemmatizer.lemmatize(word, wntag))\n",
    "    return filteredTokens\n",
    "\n",
    "text = \"Hi! My name is Rayan!\"\n",
    "ans = preprocessText(text)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68c035",
   "metadata": {},
   "source": [
    "### üìù Assignment 6: Reflection\n",
    "\n",
    "* Answer in 2‚Äì3 sentences:\n",
    "\n",
    "    * Why is context memory important in chatbots?\n",
    "    * Why should beginners always check **API limits and pricing**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ce663-992c-49bf-a6a4-b1e3bcbf81a1",
   "metadata": {},
   "source": [
    "Context memory is important in chatbots because it lets them remember previous messages, understand ongoing conversations, and provide relevant responses. API limits and pricing shall be checked to avoid unexpected costs and rate limiting issues while experimenting with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b787de4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Hints:**\n",
    "\n",
    "1) Stemming:\n",
    "    - Cuts off word endings to get the ‚Äúroot.‚Äù\n",
    "    - Very mechanical ‚Üí may produce non-real words.\n",
    "    - Example:\n",
    "        - \"studies\" ‚Üí \"studi\"\n",
    "        - \"running\" ‚Üí \"run\"\n",
    "\n",
    "2) Lemmatization:\n",
    "    - Smarter ‚Üí uses vocabulary + grammar rules.\n",
    "    - Always gives a real word (the **lemma**).\n",
    "    - Example:\n",
    "        - \"studies\" ‚Üí \"study\"\n",
    "        - \"running\" ‚Üí \"run\"\n",
    "\n",
    "3) Part-of-Speech (POS) tagging means labeling each word in a sentence with its grammatical role ‚Äî like **noun, verb, adjective, adverb, pronoun, etc.**\n",
    "\n",
    "    - Example:\n",
    "        - Sentence ‚Üí *‚ÄúThe cat is sleeping on the mat.‚Äù*\n",
    "\n",
    "    - POS tags ‚Üí\n",
    "        - The ‚Üí Determiner (DT)\n",
    "        - cat ‚Üí Noun (NN)\n",
    "        - is ‚Üí Verb (VBZ)\n",
    "        - sleeping ‚Üí Verb (VBG)\n",
    "        - on ‚Üí Preposition (IN)\n",
    "        - the ‚Üí Determiner (DT)\n",
    "        - mat ‚Üí Noun (NN)\n",
    "\n",
    "    - **In short:** POS tagging helps machines understand **how words function in a sentence**, which is useful in NLP tasks like machine translation, text classification, and question answering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec98bb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ‚úÖ Recap\n",
    "\n",
    "This week you learned:\n",
    "\n",
    "* **LLMs**: Types, uses, must-knows.\n",
    "* **STT & TTS**: How they connect with LLMs.\n",
    "* **APIs**: Connecting to LLMs with Groq.\n",
    "* Built your first chatbot foundation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
