{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e4bcdd",
   "metadata": {},
   "source": [
    "## What is RAG ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27668802",
   "metadata": {},
   "source": [
    "RAG is a technique where a language model first looks up (retrieves) useful information from a database or documents, and then uses that information to give a better answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee7c36",
   "metadata": {},
   "source": [
    "## Why and when we prefer RAG over finetuning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632852af",
   "metadata": {},
   "source": [
    "We **prefer RAG over finetuning** when: We want the model to give **up-to-date or specific answers** from **our own data** without changing the model itself.\n",
    "\n",
    "---\n",
    "\n",
    "**Why prefer RAG?**\n",
    "\n",
    "* **Cheaper & faster** – No need to train the model again.\n",
    "* **Easier to update** – Just change the documents, not the model.\n",
    "* **Better for private or large data** – You keep data separate and safe.\n",
    "\n",
    "---\n",
    "\n",
    "**When to use RAG?**\n",
    "\n",
    "* When your data **changes often** (like news, product lists).\n",
    "* When you want the model to **answer from your documents**.\n",
    "* When **training a model is too costly or slow**.\n",
    "\n",
    "---\n",
    "\n",
    "Think of RAG like **giving the model a library to read** instead of teaching it everything from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac356886",
   "metadata": {},
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0436fd6",
   "metadata": {},
   "source": [
    "* **`langchain`** – Core framework to build LLM-powered applications.\n",
    "* **`langchain-community`** – Extra integrations like tools, APIs, and vector stores.\n",
    "* **`langchain-pinecone`** – Connects LangChain with Pinecone for vector storage and retrieval.\n",
    "* **`langchain_groq`** – Enables LangChain to use Groq's ultra-fast language models.\n",
    "* **`datasets`** – Provides ready-to-use NLP/ML datasets from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65db921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain==0.3.23\n",
      "  Using cached langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community==0.3.21\n",
      "  Using cached langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-pinecone==0.2.5 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (0.2.5)\n",
      "Requirement already satisfied: langchain_groq in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (0.3.6)\n",
      "Requirement already satisfied: datasets==3.5.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (3.5.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.3.23) (0.3.79)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.3.23) (0.3.11)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.3.23) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.3.23) (2.12.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.3.23) (2.0.22)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.3.23) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain==0.3.23) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community==0.3.21) (3.10.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community==0.3.21) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community==0.3.21) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community==0.3.21) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community==0.3.21) (0.4.3)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-community==0.3.21) (1.26.4)\n",
      "Requirement already satisfied: pinecone<7.0.0,>=6.0.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone==0.2.5) (6.0.2)\n",
      "Requirement already satisfied: langchain-tests<1.0.0,>=0.3.7 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-pinecone==0.2.5) (0.3.22)\n",
      "Requirement already satisfied: filelock in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (0.35.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from datasets==3.5.0) (24.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.21) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.21) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.21) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.21) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.21) (6.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.21) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.21) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.21) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain==0.3.23) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain==0.3.23) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.51->langchain==0.3.23) (3.0.0)\n",
      "Requirement already satisfied: pytest<9.0.0,>=7.0.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (8.4.2)\n",
      "Requirement already satisfied: pytest-asyncio<2.0.0,>=0.20.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (1.2.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (0.28.1)\n",
      "Requirement already satisfied: syrupy<5.0.0,>=4.0.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (4.9.1)\n",
      "Requirement already satisfied: pytest-socket<1.0.0,>=0.7.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (0.7.0)\n",
      "Requirement already satisfied: pytest-benchmark in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (5.1.0)\n",
      "Requirement already satisfied: pytest-codspeed in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (4.1.1)\n",
      "Requirement already satisfied: pytest-recording in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (0.13.4)\n",
      "Requirement already satisfied: vcrpy<8.0.0,>=7.0.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (7.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1.0.0,>=0.28.1->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (3.7.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1.0.0,>=0.28.1->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1.0.0,>=0.28.1->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1.0.0,>=0.28.1->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (0.16.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.23) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.23) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.23) (0.23.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone==0.2.5) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone==0.2.5) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone==0.2.5) (2.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.23) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.23) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.23) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.21) (1.0.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pytest<9.0.0,>=7.0.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (0.4.6)\n",
      "Requirement already satisfied: iniconfig>=1 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pytest<9.0.0,>=7.0.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pytest<9.0.0,>=7.0.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pytest<9.0.0,>=7.0.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (2.19.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain==0.3.23) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.23) (3.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.21) (1.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from vcrpy<8.0.0,>=7.0.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (1.14.2)\n",
      "Requirement already satisfied: propcache>=0.2.1 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.21) (0.4.1)\n",
      "Requirement already satisfied: groq<1,>=0.29.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from langchain_groq) (0.32.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from groq<1,>=0.29.0->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from groq<1,>=0.29.0->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.5.3->pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone==0.2.5) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==3.5.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==3.5.0) (2025.2)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pytest-benchmark->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (9.0.0)\n",
      "Requirement already satisfied: cffi>=1.17.1 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (2.0.0)\n",
      "Requirement already satisfied: rich>=13.8.1 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (14.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from cffi>=1.17.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (2.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from rich>=13.8.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abdul\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=13.8.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone==0.2.5) (0.1.2)\n",
      "Using cached langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "Installing collected packages: langchain, langchain-community\n",
      "\n",
      "  Attempting uninstall: langchain\n",
      "\n",
      "    Found existing installation: langchain 0.3.27\n",
      "\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "    Uninstalling langchain-0.3.27:\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "      Successfully uninstalled langchain-0.3.27\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "  Attempting uninstall: langchain-community\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "    Found existing installation: langchain-community 0.3.31\n",
      "   ---------------------------------------- 0/2 [langchain]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "    Uninstalling langchain-community-0.3.31:\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "      Successfully uninstalled langchain-community-0.3.31\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   -------------------- ------------------- 1/2 [langchain-community]\n",
      "   ---------------------------------------- 2/2 [langchain-community]\n",
      "\n",
      "Successfully installed langchain-0.3.23 langchain-community-0.3.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pinecone 6.0.2 does not provide the extra 'async'\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.3.23 langchain-community==0.3.21 langchain-pinecone==0.2.5 langchain_groq datasets==3.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b00464f",
   "metadata": {},
   "source": [
    "## Load API Keys from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22aa0b2",
   "metadata": {},
   "source": [
    "### What is env file?\n",
    "\n",
    "* A .env file is a simple text file that stores environment variables (like API keys and secrets) in key=value format.\n",
    "* Example content of a .env file:\n",
    "* PINECONE_API_KEY=your_pinecone_api_key_here\n",
    "* GROQ_API_KEY=your_groq_api_key_here\n",
    "\n",
    "* It helps keep sensitive information out of your code and makes it easier to manage secrets securely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a4c86",
   "metadata": {},
   "source": [
    "**Imports tools** to:\n",
    "\n",
    "* Use environment variables (`os`)\n",
    "* Load values from a `.env` file (`load_dotenv`)\n",
    "* **os** is a Python built-in module that lets your code interact with the operating system (like Windows, macOS, Linux).\n",
    "---\n",
    "* **Loads the `.env` file** so Python can use the secret keys stored in it (like API keys).\n",
    "* **Gets the values** of `PINECONE_API_KEY` and `GROQ_API_KEY` from the `.env` file.\n",
    "* **In Short:** This code **reads your secret keys from a `.env` file** so you don’t have to write them directly in your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abe7804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages are installed.\n"
     ]
    }
   ],
   "source": [
    "print(\"All required packages are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08e6bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pinecone API Key Loaded Successfully\n",
      "✅ Groq API Key Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the keys\n",
    "pinecone_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Check if keys are loaded properly\n",
    "if pinecone_key:\n",
    "    print(\"✅ Pinecone API Key Loaded Successfully\")\n",
    "else:\n",
    "    print(\"❌ Pinecone API Key NOT Loaded\")\n",
    "\n",
    "if groq_key:\n",
    "    print(\"✅ Groq API Key Loaded Successfully\")\n",
    "else:\n",
    "    print(\"❌ Groq API Key NOT Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef1c075",
   "metadata": {},
   "source": [
    "## What is `langchain_groq`?\n",
    "\n",
    "`langchain_groq` is a **LangChain integration** that lets you **connect to Groq’s LLMs** (like LLaMA3) easily.\n",
    "\n",
    "Think of it as a **bridge between LangChain and Groq’s fast language models**.\n",
    "\n",
    "---\n",
    "\n",
    "## What is `ChatGroq`?\n",
    "\n",
    "`ChatGroq` is a **class (tool)** inside `langchain_groq`.\n",
    "\n",
    "It lets you:\n",
    "\n",
    "* **Send prompts** to Groq-hosted models\n",
    "* **Receive responses** from those models\n",
    "* Use these models in your **LangChain app**, like chatbots, RAG, agents, etc.\n",
    "\n",
    "---\n",
    "\n",
    "**Why do we use this?**\n",
    "\n",
    "Instead of manually setting up HTTP requests to Groq’s API, `ChatGroq` makes it **super easy**:\n",
    "\n",
    "* Lets you talk to a specific Groq model (`llama3-8b-8192`)\n",
    "* Works smoothly with LangChain tools (retrievers, chains, memory, etc.)\n",
    "* Connects securely with your `groq_api_key`\n",
    "\n",
    "---\n",
    "\n",
    "#### In Simple Words\n",
    "\n",
    "* `langchain_groq` lets LangChain talk to Groq.\n",
    "* `ChatGroq` is the tool that helps you **chat with Groq’s AI model** using your API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "990bfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chat = ChatGroq(\n",
    "    groq_api_key=groq_key,\n",
    "    model_name=\"llama-3.1-8b-instant\"  # Correct model name used by Groq\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09520cec",
   "metadata": {},
   "source": [
    "Groq uses the **same chat structure as OpenAI** because it runs **OpenAI-compatible models** like `llama3`, `mixtral`, etc.\n",
    "So just like OpenAI, chats with Groq **typically look like this in plain text**:\n",
    "\n",
    "```\n",
    "System: You are a helpful assistant.\n",
    "User: Hi, how are you?\n",
    "Assistant: I'm doing well! How can I assist you today?\n",
    "User: What is quantum computing?\n",
    "Assistant:\n",
    "```\n",
    "\n",
    "The final `\"Assistant:\"` without a response is what would prompt the model to continue the conversation. In the official OpenAI `ChatCompletion` endpoint these would be passed to the model in a format like:\n",
    "\n",
    "---\n",
    "\n",
    "**In Code (OpenAI/Groq-compatible format):**\n",
    "\n",
    "When using the API (like with `ChatGroq` or `ChatOpenAI` in LangChain), you use this structure:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm doing well! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**In LangChain (message objects):**\n",
    "\n",
    "LangChain wraps those into **message classes**, like:\n",
    "\n",
    "```\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi, how are you?\"),\n",
    "    AIMessage(content=\"I'm doing well! How can I assist you today?\"),\n",
    "    HumanMessage(content=\"What is quantum computing?\")\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21b712",
   "metadata": {},
   "source": [
    "The format is very similar, we're just swapped the role of `\"user\"` for `HumanMessage`, and the role of `\"assistant\"` for `AIMessage`.\n",
    "\n",
    "Then you pass them to the model:\n",
    "\n",
    "```\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8254e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aab48e",
   "metadata": {},
   "source": [
    "We generate the next response from the AI by passing these messages to the `ChatGroq` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ddade",
   "metadata": {},
   "source": [
    "Like saying to the AI:\n",
    "\n",
    "“Here’s what has been said so far — now tell me what the AI should say next.”\n",
    "\n",
    "LangChain then handles formatting and sending this to the LLM backend, and res stores the AI’s next reply.\n",
    "\n",
    "**In Short:**\n",
    "* You define a conversation (via messages).\n",
    "* Call the LLM using chat(messages).\n",
    "* Get a response back — stored in res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "109d2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d420165f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='String theory is a fundamental concept in modern physics that attempts to unify the principles of quantum mechanics and general relativity. It\\'s a complex and abstract idea, but I\\'ll try to break it down in simple terms.\\n\\n**What is string theory?**\\n\\nString theory proposes that the fundamental building blocks of the universe are not particles, but tiny, vibrating strings. These strings are too small to be seen, but they\\'re thought to be the source of all matter and energy in the universe.\\n\\n**The dimensions**\\n\\nIn our everyday experience, we have three dimensions: length, width, and depth. However, string theory suggests that there are additional dimensions beyond these three. These extra dimensions are \"curled up\" or \"compactified\" so tightly that we can\\'t directly observe them.\\n\\n**The vibrations**\\n\\nThe vibrating strings in string theory are thought to produce the various particles we observe in the universe, such as electrons, quarks, and photons. The different vibrations correspond to different particles, much like the different notes on a violin string correspond to different musical notes.\\n\\n**Types of strings**\\n\\nThere are two main types of strings in string theory:\\n\\n1. **Open strings**: These strings have free ends and can vibrate in different modes to produce different particles.\\n2. **Closed strings**: These strings are loops that can vibrate to produce particles like gravitons, which are thought to be the carriers of gravity.\\n\\n**Theories and models**\\n\\nThere are several string theories, each with its own set of assumptions and predictions. Some of the most popular ones include:\\n\\n1. **Superstring theory**: This theory proposes that the universe is made up of two types of strings: open and closed.\\n2. **M-theory**: This theory proposes that the universe is made up of one type of string: a \"membrane\" that can vibrate in different ways to produce different particles.\\n3. **String landscape**: This model proposes that there are an infinite number of possible universes, each with its own set of physical laws and properties.\\n\\n**Challenges and limitations**\\n\\nString theory is still a highly speculative and incomplete theory. While it has been successful in explaining some phenomena, it\\'s still unclear whether it\\'s a complete and consistent theory.\\n\\nSome of the challenges and limitations of string theory include:\\n\\n1. **Lack of experimental evidence**: Despite decades of research, there\\'s still no direct experimental evidence to support string theory.\\n2. **Mathematical complexity**: String theory requires advanced mathematical tools to describe the behavior of vibrating strings.\\n3. **Multiverse problem**: The string landscape model suggests that there may be an infinite number of universes, each with its own set of physical laws and properties.\\n\\n**Conclusion**\\n\\nString theory is a complex and abstract concept that attempts to unify the principles of quantum mechanics and general relativity. While it has been successful in explaining some phenomena, it\\'s still a highly speculative and incomplete theory. However, it remains one of the most promising approaches to understanding the fundamental nature of the universe.\\n\\nDo you have any specific questions about string theory?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 617, 'prompt_tokens': 79, 'total_tokens': 696, 'completion_time': 0.761412151, 'prompt_time': 0.004268743, 'queue_time': 0.045321187, 'total_time': 0.765680894}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9816cc62-6da6-4f02-ad0a-d4635deef0c6-0', usage_metadata={'input_tokens': 79, 'output_tokens': 617, 'total_tokens': 696})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f108837",
   "metadata": {},
   "source": [
    "To see the models reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "748f8abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String theory is a fundamental concept in modern physics that attempts to unify the principles of quantum mechanics and general relativity. It's a complex and abstract idea, but I'll try to break it down in simple terms.\n",
      "\n",
      "**What is string theory?**\n",
      "\n",
      "String theory proposes that the fundamental building blocks of the universe are not particles, but tiny, vibrating strings. These strings are too small to be seen, but they're thought to be the source of all matter and energy in the universe.\n",
      "\n",
      "**The dimensions**\n",
      "\n",
      "In our everyday experience, we have three dimensions: length, width, and depth. However, string theory suggests that there are additional dimensions beyond these three. These extra dimensions are \"curled up\" or \"compactified\" so tightly that we can't directly observe them.\n",
      "\n",
      "**The vibrations**\n",
      "\n",
      "The vibrating strings in string theory are thought to produce the various particles we observe in the universe, such as electrons, quarks, and photons. The different vibrations correspond to different particles, much like the different notes on a violin string correspond to different musical notes.\n",
      "\n",
      "**Types of strings**\n",
      "\n",
      "There are two main types of strings in string theory:\n",
      "\n",
      "1. **Open strings**: These strings have free ends and can vibrate in different modes to produce different particles.\n",
      "2. **Closed strings**: These strings are loops that can vibrate to produce particles like gravitons, which are thought to be the carriers of gravity.\n",
      "\n",
      "**Theories and models**\n",
      "\n",
      "There are several string theories, each with its own set of assumptions and predictions. Some of the most popular ones include:\n",
      "\n",
      "1. **Superstring theory**: This theory proposes that the universe is made up of two types of strings: open and closed.\n",
      "2. **M-theory**: This theory proposes that the universe is made up of one type of string: a \"membrane\" that can vibrate in different ways to produce different particles.\n",
      "3. **String landscape**: This model proposes that there are an infinite number of possible universes, each with its own set of physical laws and properties.\n",
      "\n",
      "**Challenges and limitations**\n",
      "\n",
      "String theory is still a highly speculative and incomplete theory. While it has been successful in explaining some phenomena, it's still unclear whether it's a complete and consistent theory.\n",
      "\n",
      "Some of the challenges and limitations of string theory include:\n",
      "\n",
      "1. **Lack of experimental evidence**: Despite decades of research, there's still no direct experimental evidence to support string theory.\n",
      "2. **Mathematical complexity**: String theory requires advanced mathematical tools to describe the behavior of vibrating strings.\n",
      "3. **Multiverse problem**: The string landscape model suggests that there may be an infinite number of universes, each with its own set of physical laws and properties.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "String theory is a complex and abstract concept that attempts to unify the principles of quantum mechanics and general relativity. While it has been successful in explaining some phenomena, it's still a highly speculative and incomplete theory. However, it remains one of the most promising approaches to understanding the fundamental nature of the universe.\n",
      "\n",
      "Do you have any specific questions about string theory?\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d2d69",
   "metadata": {},
   "source": [
    "Because `res` is just another `AIMessage` object, we can append it to `messages`, add another `HumanMessage`, and generate the next response in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36c75ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory can produce a unified theory because it attempts to reconcile two major frameworks of physics:\n",
      "\n",
      "1. **General Relativity (GR)**: Describes the behavior of gravity and the large-scale structure of the universe.\n",
      "2. **Quantum Mechanics (QM)**: Describes the behavior of particles at the atomic and subatomic level.\n",
      "\n",
      "**The problem**\n",
      "\n",
      "The problem is that these two theories are incompatible within the framework of classical physics. GR describes the universe as a smooth, continuous fabric, while QM describes the universe as made up of discrete, grainy particles. This incompatibility is known as the \"quantum gravity problem.\"\n",
      "\n",
      "**String theory's potential solution**\n",
      "\n",
      "String theory proposes that the fundamental building blocks of the universe are one-dimensional strings rather than point-like particles. These strings can vibrate at different frequencies, producing the various particles we observe in the universe. This idea attempts to reconcile GR and QM in several ways:\n",
      "\n",
      "1. **Unifying forces**: String theory proposes that all fundamental forces, including gravity, electromagnetism, and the strong and weak nuclear forces, are different vibrations of the same string.\n",
      "2. **Discrete spectrum**: The vibrations of the string produce a discrete spectrum of particles, which is consistent with QM.\n",
      "3. **Continuous geometry**: The string's vibrations also produce a continuous geometry, which is consistent with GR.\n",
      "\n",
      "**Key features of string theory**\n",
      "\n",
      "String theory has several key features that make it a promising candidate for a unified theory:\n",
      "\n",
      "1. **Background independence**: String theory does not require a fixed background geometry, unlike GR. This means that the theory can describe the dynamics of the universe from the very beginning.\n",
      "2. **Holographic principle**: String theory's holographic principle suggests that the information contained in a region of space can be encoded on its surface. This idea is consistent with the concept of black hole entropy.\n",
      "3. **Calabi-Yau manifolds**: String theory requires the existence of Calabi-Yau manifolds, which are complex geometric structures that can provide a framework for unifying the forces.\n",
      "\n",
      "**Why string theory is a candidate for a unified theory**\n",
      "\n",
      "String theory's combination of features makes it a promising candidate for a unified theory:\n",
      "\n",
      "1. **Unifies forces**: String theory proposes that all fundamental forces are different vibrations of the same string.\n",
      "2. **Reconciles GR and QM**: String theory attempts to reconcile the discrete spectrum of QM with the continuous geometry of GR.\n",
      "3. **Provides a framework for background independence**: String theory's holographic principle and Calabi-Yau manifolds provide a framework for describing the dynamics of the universe from the very beginning.\n",
      "\n",
      "However, it's essential to note that string theory is still a highly speculative and incomplete theory. While it has been successful in explaining some phenomena, it's still unclear whether it's a complete and consistent theory.\n",
      "\n",
      "Do you have any specific questions about the unification of forces or the reconciliation of GR and QM in string theory?\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Why do physicists believe it can produce a 'unified theory'?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c7774",
   "metadata": {},
   "source": [
    "## Dealing with Hallucinations\n",
    "\n",
    "We have our chatbot, but as mentioned — the knowledge of LLMs can be limited. The reason for this is that LLMs learn all they know during training. An LLM essentially compresses the \"world\" as seen in the training data into the internal parameters of the model. We call this knowledge the _parametric knowledge_ of the model.\n",
    "\n",
    "By default, LLMs have no access to the external world.\n",
    "\n",
    "The result of this is very clear when we ask LLMs about more recent information, like about Deepseek R1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d2b6ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory can produce a unified theory because it attempts to reconcile two major frameworks of physics:\n",
      "\n",
      "1. **General Relativity (GR)**: Describes the behavior of gravity and the large-scale structure of the universe.\n",
      "2. **Quantum Mechanics (QM)**: Describes the behavior of particles at the atomic and subatomic level.\n",
      "\n",
      "**The problem**\n",
      "\n",
      "The problem is that these two theories are incompatible within the framework of classical physics. GR describes the universe as a smooth, continuous fabric, while QM describes the universe as made up of discrete, grainy particles. This incompatibility is known as the \"quantum gravity problem.\"\n",
      "\n",
      "**String theory's potential solution**\n",
      "\n",
      "String theory proposes that the fundamental building blocks of the universe are one-dimensional strings rather than point-like particles. These strings can vibrate at different frequencies, producing the various particles we observe in the universe. This idea attempts to reconcile GR and QM in several ways:\n",
      "\n",
      "1. **Unifying forces**: String theory proposes that all fundamental forces, including gravity, electromagnetism, and the strong and weak nuclear forces, are different vibrations of the same string.\n",
      "2. **Discrete spectrum**: The vibrations of the string produce a discrete spectrum of particles, which is consistent with QM.\n",
      "3. **Continuous geometry**: The string's vibrations also produce a continuous geometry, which is consistent with GR.\n",
      "\n",
      "**Key features of string theory**\n",
      "\n",
      "String theory has several key features that make it a promising candidate for a unified theory:\n",
      "\n",
      "1. **Background independence**: String theory does not require a fixed background geometry, unlike GR. This means that the theory can describe the dynamics of the universe from the very beginning.\n",
      "2. **Holographic principle**: String theory's holographic principle suggests that the information contained in a region of space can be encoded on its surface. This idea is consistent with the concept of black hole entropy.\n",
      "3. **Calabi-Yau manifolds**: String theory requires the existence of Calabi-Yau manifolds, which are complex geometric structures that can provide a framework for unifying the forces.\n",
      "\n",
      "**Why string theory is a candidate for a unified theory**\n",
      "\n",
      "String theory's combination of features makes it a promising candidate for a unified theory:\n",
      "\n",
      "1. **Unifies forces**: String theory proposes that all fundamental forces are different vibrations of the same string.\n",
      "2. **Reconciles GR and QM**: String theory attempts to reconcile the discrete spectrum of QM with the continuous geometry of GR.\n",
      "3. **Provides a framework for background independence**: String theory's holographic principle and Calabi-Yau manifolds provide a framework for describing the dynamics of the universe from the very beginning.\n",
      "\n",
      "However, it's essential to note that string theory is still a highly speculative and incomplete theory. While it has been successful in explaining some phenomena, it's still unclear whether it's a complete and consistent theory.\n",
      "\n",
      "Do you have any specific questions about the unification of forces or the reconciliation of GR and QM in string theory?\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8794be3e",
   "metadata": {},
   "source": [
    "Our chatbot can no longer help us, it doesn't contain the information we need to answer the question. It was very clear from this answer that the LLM doesn't know the informaiton, but sometimes an LLM may respond like it _does_ know the answer — and this can be very hard to detect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e10521",
   "metadata": {},
   "source": [
    "## Alternate Way : Source Knowledge\n",
    "\n",
    "There is another way of feeding knowledge into LLMs. It is called _source knowledge_ and it refers to any information fed into the LLM via the prompt. We can try that with the Deepseek question. We can take the paper abstract from the [Deepseek R1 paper](https://arxiv.org/abs/2501.12948)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9af49e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_knowledge = (\n",
    "    \"We introduce our first-generation reasoning models, DeepSeek-R1-Zero and \"\n",
    "    \"DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale \"\n",
    "    \"reinforcement learning (RL) without supervised fine-tuning (SFT) as a \"\n",
    "    \"preliminary step, demonstrates remarkable reasoning capabilities. Through \"\n",
    "    \"RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and \"\n",
    "    \"intriguing reasoning behaviors. However, it encounters challenges such as \"\n",
    "    \"poor readability, and language mixing. To address these issues and \"\n",
    "    \"further enhance reasoning performance, we introduce DeepSeek-R1, which \"\n",
    "    \"incorporates multi-stage training and cold-start data before RL. \"\n",
    "    \"DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on \"\n",
    "    \"reasoning tasks. To support the research community, we open-source \"\n",
    "    \"DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, \"\n",
    "    \"32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeffaa08",
   "metadata": {},
   "source": [
    "We can feed this additional knowledge into our prompt with some instructions telling the LLM how we'd like it to use this information alongside our original query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40297f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is so special about Deepseek R1?\"\n",
    "\n",
    "augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf6bb0",
   "metadata": {},
   "source": [
    "Now we feed this into our chatbot as we were before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa5b6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augmented_prompt\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "322c6993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, the contexts you provided don't mention anything about physics or string theory. They actually describe a new AI model called DeepSeek-R1 and its variants, which are designed to improve reasoning capabilities in language tasks.\n",
      "\n",
      "However, if you'd like to continue exploring the context of string theory and unified theories, I can try to answer your original question.\n",
      "\n",
      "Physicists believe that string theory can produce a unified theory because it attempts to reconcile two major theories:\n",
      "\n",
      "1. **General Relativity (GR)**: Describes the behavior of gravity and the large-scale structure of the universe.\n",
      "2. **Quantum Mechanics (QM)**: Describes the behavior of particles at the atomic and subatomic level.\n",
      "\n",
      "GR and QM are fundamental theories that have been incredibly successful in their respective domains, but they're fundamentally incompatible within the framework of classical physics. GR is a classical theory that describes the smooth, continuous behavior of gravity, while QM is a quantum theory that describes the discrete, probabilistic behavior of particles.\n",
      "\n",
      "String theory attempts to unify GR and QM by proposing that the fundamental building blocks of the universe (strings) are one-dimensional objects that vibrate at different frequencies, giving rise to the various particles we observe. This attempt to reconcile the principles of GR and QM is what makes string theory a candidate for a unified theory.\n",
      "\n",
      "Some of the key reasons why physicists believe that string theory can produce a unified theory include:\n",
      "\n",
      "1. **Unification of forces**: String theory proposes that the fundamental forces of nature (gravity, electromagnetism, and the strong and weak nuclear forces) are all manifestations of vibrations of the same underlying string.\n",
      "2. **Quantization of gravity**: String theory provides a framework for quantizing gravity, which is a major challenge in the development of a unified theory.\n",
      "3. **Predictive power**: String theory makes predictions about the behavior of particles and forces that can be tested experimentally, which is essential for any scientific theory.\n",
      "\n",
      "However, as I mentioned earlier, string theory is still a highly speculative and incomplete theory, and much more work is needed to confirm its predictions and develop a complete and consistent theory of everything.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b235b09",
   "metadata": {},
   "source": [
    "## How do we get this information in the first place?\n",
    "\n",
    "The quality of this answer is phenomenal. This is made possible thanks to the idea of augmented our query with external knowledge (source knowledge). There's just one problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b79b1",
   "metadata": {},
   "source": [
    "This is where Pinecone and vector databases comes in place, as they can help us here too. But first, we'll need a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b633b59",
   "metadata": {},
   "source": [
    "## Importing the Data\n",
    "\n",
    "In this task, we will be importing our data. We will be using the Hugging Face Datasets library to load our data. Specifically, we will be using the `\"jamescalam/deepseek-r1-paper-chunked\"` dataset. This dataset contains the Deepseek R1 paper pre-processed into RAG-ready chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c79b46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['doi', 'chunk-id', 'chunk', 'num_tokens', 'pages', 'source'],\n",
       "    num_rows: 76\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"jamescalam/deepseek-r1-paper-chunked\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c9178a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doi': '2501.12948v1',\n",
       " 'chunk-id': 1,\n",
       " 'chunk': \"uestion: If a > 1, then the sum of the real solutions of √a - √a + x = x is equal to Response: <think> To solve the equation √a – √a + x = x, let's start by squaring both . . . (√a-√a+x)² = x² ⇒ a - √a + x = x². Rearrange to isolate the inner square root term:(a – x²)² = a + x ⇒ a² – 2ax² + (x²)² = a + x ⇒ x⁴ - 2ax² - x + (a² – a) = 0\",\n",
       " 'num_tokens': 145,\n",
       " 'pages': [1],\n",
       " 'source': 'https://arxiv.org/abs/2501.12948'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81d343",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "The dataset we are using is sourced from the Deepseek R1 ArXiv papers. Each entry in the dataset represents a \"chunk\" of text from the R1 paper.\n",
    "\n",
    "Because most **L**arge **L**anguage **M**odels (LLMs) only contain knowledge of the world as it was during training, even many of the newest LLMs cannot answer questions about Deepseek R1 — at least not without this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a0ede",
   "metadata": {},
   "source": [
    "## Building the Knowledge Base\n",
    "\n",
    "We now have a dataset that can serve as our chatbot knowledge base. Our next task is to transform that dataset into the knowledge base that our chatbot can use. To do this we must use an embedding model and vector database.\n",
    "\n",
    "We begin by initializing our Pinecone client, this requires a [free API key](https://app.pinecone.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fd4159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# initialize client\n",
    "pc = Pinecone(api_key=pinecone_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78b484",
   "metadata": {},
   "source": [
    "Delete the old one to save the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4aa6f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"rag1\"\n",
    "\n",
    "pc.delete_index(index_name)  # delete old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "545e1533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"rag1\",\n",
       "    \"metric\": \"dotproduct\",\n",
       "    \"host\": \"rag1-ldgnxmm.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec, CloudProvider, AwsRegion, Metric\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    metric=Metric.DOTPRODUCT,\n",
    "    dimension=384,  # ✅ match your embedding model\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=CloudProvider.AWS,\n",
    "        region=AwsRegion.US_EAST_1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df29057",
   "metadata": {},
   "source": [
    "Our index is now ready but it's empty. It is a vector index, so it needs vectors. As mentioned, to create these vector embeddings we will HuggingFace's `sentence-transformers/all-MiniLM-L6-v2` model — we can access it via LangChain like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd405ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9229b3d",
   "metadata": {},
   "source": [
    "Using this model we can create embeddings like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5daf97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed_model.embed_documents(texts)\n",
    "len(res), len(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ea6f5",
   "metadata": {},
   "source": [
    "From this we get two (aligning to our two chunks of text) CHANGE-dimensional embeddings.\n",
    "\n",
    "We're now ready to embed and index all our our data! We do this by looping through our dataset and embedding and inserting everything in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88b28f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0cdf8cc488447fb22f5bb069d6971d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm  # for progress bar\n",
    "\n",
    "data = dataset.to_pandas()  # this makes it easier to iterate over the dataset\n",
    "index = pc.Index(index_name)\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    # get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # generate unique ids for each chunk\n",
    "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n",
    "    # get text to embed\n",
    "    texts = [x['chunk'] for _, x in batch.iterrows()]\n",
    "    # embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['chunk'],\n",
    "         'source': x['source']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e4fa5",
   "metadata": {},
   "source": [
    "We can check that the vector index has been populated using `describe_index_stats` like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f56bb113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'dotproduct',\n",
       " 'namespaces': {'': {'vector_count': 76}},\n",
       " 'total_vector_count': 76,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e988a",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86c59e",
   "metadata": {},
   "source": [
    "We've built a fully-fledged knowledge base. Now it's time to link that knowledge base to our chatbot. To do that we'll be diving back into LangChain and reusing our template prompt from earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb42eae",
   "metadata": {},
   "source": [
    "To use LangChain here we need to load the LangChain abstraction for a vector index, called a `vectorstore`. We pass in our vector `index` to initialize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b9846ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embed_model,\n",
    "    text_key=text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799256a3",
   "metadata": {},
   "source": [
    "Using this `vectorstore` we can already query the index and see if we have any relevant information given our question about Llama 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3214e3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='2501.12948v1-39', metadata={'source': 'https://arxiv.org/abs/2501.12948'}, page_content='## 1.2. Summary of Evaluation Results - **Reasoning tasks:** (1) DeepSeek-R1 achieves a score of 79.8% Pass@1 on AIME 2024, slightly surpassing OpenAI-01-1217. On MATH-500, it attains an impressive score of 97.3%, performing on par with OpenAI-01-1217 and significantly outperforming other models. (2) On coding-related tasks, DeepSeek-R1 demonstrates expert level in code competition tasks, as it achieves 2,029 Elo rating on Codeforces outperforming 96.3% human participants in the competition. For engineering-related tasks, DeepSeek-R1 performs slightly better than DeepSeek-V3, which could help developers in real world tasks. - **Knowledge:** On benchmarks such as MMLU, MMLU-Pro, and GPQA Diamond, DeepSeek-R1 achieves outstanding results, significantly outperforming DeepSeek-V3 with scores of 90.8% on MMLU, 84.0% on MMLU-Pro, and 71.5% on GPQA Diamond. While its performance is slightly below that of OpenAI-01-1217 on these benchmarks, DeepSeek-R1 surpasses other closed-source models, demonstrating its competitive edge in educational tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3, demonstrating its capability in handling fact-based queries. A similar trend is observed where OpenAI-01 surpasses 4o on this benchmark.'),\n",
       " Document(id='2501.12948v1-56', metadata={'source': 'https://arxiv.org/abs/2501.12948'}, page_content='Table summary:\\nTable 5 presents a comparison of DeepSeek-R1 distilled models against other leading models across various reasoning-related benchmarks, including AIME 2024, MATH-500, GPQA Diamond, LiveCode Bench, and CodeForces. The metrics evaluated are pass@1 and cons@64. \\nNotably, the DeepSeek-R1-Distill-Qwen-32B model achieves the highest score in AIME 2024 with 72.6, while the DeepSeek-R1-Distill-Llama-70B excels in MATH-500 with 86.7. In GPQA Diamond, the DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Llama-70B models lead with scores of 94.3 and 94.5, respectively. \\nOverall, the DeepSeek-R1 models demonstrate competitive performance, particularly the 14B and 32B variants, which consistently rank high across multiple benchmarks. In contrast, models like GPT-4o-0513 and Claude-3.5-Sonnet-1022 show lower performance, especially in AIME 2024 and MATH-500. This analysis highlights the effectiveness of the DeepSeek-R1 distilled models in reasoning tasks, showcasing their potential for further applications in AI-driven reasoning solutions.\\nTable 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on\\nreasoning-related benchmarks.\\n| Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces |\\n| --- | --- | --- | --- | --- | --- |\\n|  | pass@1 | cons@64 | pass@1 | pass@1 | pass@1 |\\n| GPT-4o-0513 | 9.3 | 13.4 | 74.6 | 49.9 | 32.9 |\\n| Claude-3.5-Sonnet-1022 | 16.0 | 26.7 | 78.3 | 65.0 | 38.9 |\\n| OpenAI-o1-mini | 63.6 | 80.0 | 90.0 | 60.0 | 53.8 |\\n| QwQ-32B-Preview | 50.0 | 60.0 | 90.6 | 54.5 | 41.9 |\\n| DeepSeek-R1-Distill-Qwen-1.5B | 28.9 | 52.7 | 83.9 | 33.8 | 16.9 |\\n| DeepSeek-R1-Distill-Qwen-7B | 55.5 | 83.3 | 92.8 | 49.1 | 37.6 |\\n| DeepSeek-R1-Distill-Qwen-14B | 69.7 | 80.0 | 93.9 | 59.1 | 53.1 |\\n| DeepSeek-R1-Distill-Qwen-32B | **72.6** | 83.3 | 94.3 | 62.1 | 57.2 |\\n| DeepSeek-R1-Distill-Llama-8B | 50.4 | 80.0 | 89.1 | 49.0 | 39.6 |\\n| DeepSeek-R1-Distill-Llama-70B | 70.0 | **86.7** | **94.5** | **65.2** | **57.5** |'),\n",
       " Document(id='2501.12948v1-4', metadata={'source': 'https://arxiv.org/abs/2501.12948'}, page_content='Table summary:\\nThe table presents performance metrics for various AI models across different benchmarks, including AIME 2024, Codeforces, GPQA Diamond, MATH-500, and MMLU, measured in accuracy and percentile scores. \\nDeepSeek-R1 shows strong performance with scores of 96.3% and 96.6% at the highest accuracy level (100), while OpenAI-01-1217 achieves 97.3% and 96.4% in the same category. DeepSeek-R1-32B and OpenAI-01-mini exhibit lower scores, particularly in the 80 percentile range, where DeepSeek-V3 performs well with scores of 90.8% and 91.8%. \\nAt lower accuracy levels (60 and 40), DeepSeek models maintain competitive scores, with DeepSeek-R1 recording 72.6% and 39.2% respectively. The table highlights the varying strengths of each model across different tasks, indicating that DeepSeek models generally excel in higher accuracy ranges, while OpenAI models show robust performance in specific benchmarks. This comparative analysis aids in understanding the capabilities and limitations of each AI model in diverse applications.\\n|  | DeepSeek-R1 | OpenAI-01-1217 | DeepSeek-R1-32B | OpenAI-01-mini | DeepSeek-V3 |\\n| --- | --- | --- | --- | --- | --- |\\n|  |  |  |  |  |  |\\n|  |  |  |  |  |  |\\n| 100 |  |  |  |  |  |\\n|  | 96.3 96.6 |  | 97.3 96.4 |  |  |\\n|  |  | 93.4 |  | 94.3 |  |\\n|  |  | 90.6 |  | 90.0 90.2 |  |\\n| 80 | 79.8 79.2 |  |  | 90.8 91.8 | 88.5 |\\n|  |  |  |  |  | 87.4 |\\n|  |  |  |  |  | 85.2 |\\n|  | 72.6 |  |  |  |  |\\n|  |  |  | 75.7 |  |  |\\n|  |  |  | 71.5 |  |  |\\n|  | 63.6 |  | 62.1 |  |  |\\n|  |  |  | 60.0 59.1 |  |  |\\n| 60 |  | 58.7 |  |  |  |\\n| Accuracy / Percentile (%) |  |  |  |  |  |\\n| 40 |  |  |  |  |  |\\n|  | 39.2 |  |  |  |  |\\n| 20 |  |  |  |  |  |\\n| 0 |  |  |  |  |  |\\n|  | AIME 2024 (Pass@1) | Codeforces (Percentile) | GPQA Diamond (Pass@1) | MATH-500 (Pass@1) | MMLU (Pass@1) |\\n|  |  |  |  |  |  |\\n|  |  |  |  |  |  |\\n|  |  |  |  |  |  |')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is so special about Deepseek R1?\"\n",
    "\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fcb169",
   "metadata": {},
   "source": [
    "We return a lot of text here and it's not that clear what we need or what is relevant. Fortunately, our LLM will be able to parse this information much faster than us. All we need is to link the output from our `vectorstore` to our `chat` chatbot. To do that we can use the same logic as we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25a15337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a526be0",
   "metadata": {},
   "source": [
    "Using this we produce an augmented prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "769766aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "    Contexts:\n",
      "    ## 1.2. Summary of Evaluation Results - **Reasoning tasks:** (1) DeepSeek-R1 achieves a score of 79.8% Pass@1 on AIME 2024, slightly surpassing OpenAI-01-1217. On MATH-500, it attains an impressive score of 97.3%, performing on par with OpenAI-01-1217 and significantly outperforming other models. (2) On coding-related tasks, DeepSeek-R1 demonstrates expert level in code competition tasks, as it achieves 2,029 Elo rating on Codeforces outperforming 96.3% human participants in the competition. For engineering-related tasks, DeepSeek-R1 performs slightly better than DeepSeek-V3, which could help developers in real world tasks. - **Knowledge:** On benchmarks such as MMLU, MMLU-Pro, and GPQA Diamond, DeepSeek-R1 achieves outstanding results, significantly outperforming DeepSeek-V3 with scores of 90.8% on MMLU, 84.0% on MMLU-Pro, and 71.5% on GPQA Diamond. While its performance is slightly below that of OpenAI-01-1217 on these benchmarks, DeepSeek-R1 surpasses other closed-source models, demonstrating its competitive edge in educational tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3, demonstrating its capability in handling fact-based queries. A similar trend is observed where OpenAI-01 surpasses 4o on this benchmark.\n",
      "Table summary:\n",
      "Table 5 presents a comparison of DeepSeek-R1 distilled models against other leading models across various reasoning-related benchmarks, including AIME 2024, MATH-500, GPQA Diamond, LiveCode Bench, and CodeForces. The metrics evaluated are pass@1 and cons@64. \n",
      "Notably, the DeepSeek-R1-Distill-Qwen-32B model achieves the highest score in AIME 2024 with 72.6, while the DeepSeek-R1-Distill-Llama-70B excels in MATH-500 with 86.7. In GPQA Diamond, the DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Llama-70B models lead with scores of 94.3 and 94.5, respectively. \n",
      "Overall, the DeepSeek-R1 models demonstrate competitive performance, particularly the 14B and 32B variants, which consistently rank high across multiple benchmarks. In contrast, models like GPT-4o-0513 and Claude-3.5-Sonnet-1022 show lower performance, especially in AIME 2024 and MATH-500. This analysis highlights the effectiveness of the DeepSeek-R1 distilled models in reasoning tasks, showcasing their potential for further applications in AI-driven reasoning solutions.\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on\n",
      "reasoning-related benchmarks.\n",
      "| Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces |\n",
      "| --- | --- | --- | --- | --- | --- |\n",
      "|  | pass@1 | cons@64 | pass@1 | pass@1 | pass@1 |\n",
      "| GPT-4o-0513 | 9.3 | 13.4 | 74.6 | 49.9 | 32.9 |\n",
      "| Claude-3.5-Sonnet-1022 | 16.0 | 26.7 | 78.3 | 65.0 | 38.9 |\n",
      "| OpenAI-o1-mini | 63.6 | 80.0 | 90.0 | 60.0 | 53.8 |\n",
      "| QwQ-32B-Preview | 50.0 | 60.0 | 90.6 | 54.5 | 41.9 |\n",
      "| DeepSeek-R1-Distill-Qwen-1.5B | 28.9 | 52.7 | 83.9 | 33.8 | 16.9 |\n",
      "| DeepSeek-R1-Distill-Qwen-7B | 55.5 | 83.3 | 92.8 | 49.1 | 37.6 |\n",
      "| DeepSeek-R1-Distill-Qwen-14B | 69.7 | 80.0 | 93.9 | 59.1 | 53.1 |\n",
      "| DeepSeek-R1-Distill-Qwen-32B | **72.6** | 83.3 | 94.3 | 62.1 | 57.2 |\n",
      "| DeepSeek-R1-Distill-Llama-8B | 50.4 | 80.0 | 89.1 | 49.0 | 39.6 |\n",
      "| DeepSeek-R1-Distill-Llama-70B | 70.0 | **86.7** | **94.5** | **65.2** | **57.5** |\n",
      "Table summary:\n",
      "The table presents performance metrics for various AI models across different benchmarks, including AIME 2024, Codeforces, GPQA Diamond, MATH-500, and MMLU, measured in accuracy and percentile scores. \n",
      "DeepSeek-R1 shows strong performance with scores of 96.3% and 96.6% at the highest accuracy level (100), while OpenAI-01-1217 achieves 97.3% and 96.4% in the same category. DeepSeek-R1-32B and OpenAI-01-mini exhibit lower scores, particularly in the 80 percentile range, where DeepSeek-V3 performs well with scores of 90.8% and 91.8%. \n",
      "At lower accuracy levels (60 and 40), DeepSeek models maintain competitive scores, with DeepSeek-R1 recording 72.6% and 39.2% respectively. The table highlights the varying strengths of each model across different tasks, indicating that DeepSeek models generally excel in higher accuracy ranges, while OpenAI models show robust performance in specific benchmarks. This comparative analysis aids in understanding the capabilities and limitations of each AI model in diverse applications.\n",
      "|  | DeepSeek-R1 | OpenAI-01-1217 | DeepSeek-R1-32B | OpenAI-01-mini | DeepSeek-V3 |\n",
      "| --- | --- | --- | --- | --- | --- |\n",
      "|  |  |  |  |  |  |\n",
      "|  |  |  |  |  |  |\n",
      "| 100 |  |  |  |  |  |\n",
      "|  | 96.3 96.6 |  | 97.3 96.4 |  |  |\n",
      "|  |  | 93.4 |  | 94.3 |  |\n",
      "|  |  | 90.6 |  | 90.0 90.2 |  |\n",
      "| 80 | 79.8 79.2 |  |  | 90.8 91.8 | 88.5 |\n",
      "|  |  |  |  |  | 87.4 |\n",
      "|  |  |  |  |  | 85.2 |\n",
      "|  | 72.6 |  |  |  |  |\n",
      "|  |  |  | 75.7 |  |  |\n",
      "|  |  |  | 71.5 |  |  |\n",
      "|  | 63.6 |  | 62.1 |  |  |\n",
      "|  |  |  | 60.0 59.1 |  |  |\n",
      "| 60 |  | 58.7 |  |  |  |\n",
      "| Accuracy / Percentile (%) |  |  |  |  |  |\n",
      "| 40 |  |  |  |  |  |\n",
      "|  | 39.2 |  |  |  |  |\n",
      "| 20 |  |  |  |  |  |\n",
      "| 0 |  |  |  |  |  |\n",
      "|  | AIME 2024 (Pass@1) | Codeforces (Percentile) | GPQA Diamond (Pass@1) | MATH-500 (Pass@1) | MMLU (Pass@1) |\n",
      "|  |  |  |  |  |  |\n",
      "|  |  |  |  |  |  |\n",
      "|  |  |  |  |  |  |\n",
      "\n",
      "    Query: What is so special about Deepseek R1?\n"
     ]
    }
   ],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59e5e8",
   "metadata": {},
   "source": [
    "There is still a lot of text here, so let's pass it onto our chat model to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8a399de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided contexts, DeepSeek R1 is special for several reasons:\n",
      "\n",
      "1. **Exceptional performance in reasoning tasks**: DeepSeek R1 achieves a score of 79.8% Pass@1 on AIME 2024, slightly surpassing OpenAI-01-1217. It also attains an impressive score of 97.3% on MATH-500, performing on par with OpenAI-01-1217.\n",
      "2. **Expert-level performance in code competition tasks**: DeepSeek R1 demonstrates expert-level performance in code competition tasks, achieving a 2,029 Elo rating on Codeforces, outperforming 96.3% of human participants.\n",
      "3. **Competitive performance across multiple benchmarks**: DeepSeek R1 performs competitively across multiple benchmarks, including AIME 2024, MATH-500, GPQA Diamond, LiveCode Bench, and CodeForces.\n",
      "4. **Strong performance in educational tasks**: DeepSeek R1 outperforms other closed-source models on educational tasks, such as MMLU, MMLU-Pro, and GPQA Diamond, achieving scores of 90.8% on MMLU, 84.0% on MMLU-Pro, and 71.5% on GPQA Diamond.\n",
      "5. **Ability to handle fact-based queries**: DeepSeek R1 outperforms DeepSeek-V3 on the factual benchmark SimpleQA, demonstrating its capability in handling fact-based queries.\n",
      "6. **Consistent performance across different tasks**: DeepSeek R1 maintains competitive scores across different tasks, with strong performance in higher accuracy ranges and robust performance in specific benchmarks.\n",
      "\n",
      "Overall, DeepSeek R1's exceptional performance in reasoning tasks, code competition tasks, and educational tasks make it a special model that demonstrates strong capabilities in various applications.\n"
     ]
    }
   ],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(query)\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d917fe",
   "metadata": {},
   "source": [
    "We can continue with another Deepseek R1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cadefe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, there is no direct comparison between DeepSeek-R1 and DeepSeek-R1-Zero in the given contexts. However, I can provide some information on the two models.\n",
      "\n",
      "DeepSeek-R1-Zero is a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step. It demonstrates remarkable reasoning capabilities, but it encounters challenges such as poor readability and language mixing.\n",
      "\n",
      "DeepSeek-R1, on the other hand, is a more advanced model that incorporates multi-stage training and cold-start data before RL. It achieves performance comparable to OpenAI-o1-1217 on reasoning tasks.\n",
      "\n",
      "In general, it appears that DeepSeek-R1 is a more refined and advanced model than DeepSeek-R1-Zero, with improved performance and capabilities. However, DeepSeek-R1-Zero is still a remarkable model in its own right, with impressive reasoning capabilities despite its limitations.\n",
      "\n",
      "If you're looking for a direct comparison between the two models, I would recommend searching for additional contexts or information that specifically compares their performance.\n"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(\n",
    "        \"how does deepseek r1 compare to deepseek r1 zero?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef84ba",
   "metadata": {},
   "source": [
    "You can continue asking questions about Deepseek R1, but once you're done you can delete the index to save resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49ac1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e936cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
